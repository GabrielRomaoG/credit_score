{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from credit_score_2.cs2_preprocessing import Cs2DataSetPreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_val_score, cross_validate\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = pd.read_csv(\"credit_score_dataset_2.csv\", low_memory=False)\n",
    "\n",
    "credit_df = Cs2DataSetPreProcessing.process(credit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good', 'standard', 'poor'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = credit_df[\"credit_score\"]\n",
    "X = credit_df.drop(\"credit_score\", axis=1)\n",
    "\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEnconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(\"object\").columns\n",
    "\n",
    "col_trans = ColumnTransformer(\n",
    "    [\n",
    "        (\"ohe\", OneHotEncoder(), categorical_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=LogisticRegression(), step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "accuracy: [0.79576]\n",
      "accuracy: {'clf__n_neighbors': 2, 'rfe__n_features_to_select': 7}\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_pipe = Pipeline(\n",
    "    [\n",
    "        (\"cols_trans\", col_trans),\n",
    "        (\"scaler\", scaler),\n",
    "        (\"rfe\", rfe),\n",
    "        (\"clf\", knn)\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"rfe__n_features_to_select\": [6, 7, 8],\n",
    "    \"clf__n_neighbors\": [2, 3, 5,],\n",
    "}\n",
    "\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn_pipe, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "outer_valid = ShuffleSplit(n_splits=1, test_size=0.25, random_state=2)\n",
    "\n",
    "results_knn = cross_validate(\n",
    "    estimator=grid_search_knn,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=outer_valid,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "print(f\"accuracy: {results_knn['test_score']}\")\n",
    "print(f\"accuracy: {results_knn['estimator'][0].best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num_bank_accounts', 'num_credit_card', 'num_of_loan',\n",
       "       'num_of_delayed_payment', 'outstanding_debt', 'credit_history_age',\n",
       "       'total_emi_per_month'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_features = results_knn[\"estimator\"][0].best_estimator_.named_steps[\"rfe\"].get_support()\n",
    "cols = results_knn[\"estimator\"][0].best_estimator_.named_steps[\"cols_trans\"].get_feature_names_out()\n",
    "\n",
    "cols[mask_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rfe = X[cols[mask_features]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "accuracy: 0.5931599999999999\n",
      "accuracy: {'logreg__alpha': np.float64(1e-05), 'logreg__l1_ratio': np.float64(0.5)}\n"
     ]
    }
   ],
   "source": [
    "logreg = SGDClassifier(loss=\"log_loss\", max_iter=10000)\n",
    "\n",
    "logreg_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", scaler),\n",
    "        (\"logreg\", logreg)\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"logreg__alpha\": np.logspace(-5, 1, 5),\n",
    "    \"logreg__l1_ratio\": np.linspace(0, 1, 5),\n",
    "}\n",
    "\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    logreg_pipe, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "outer_valid = ShuffleSplit(n_splits=1, test_size=0.25, random_state=2)\n",
    "\n",
    "results_log = cross_validate(\n",
    "    estimator=grid_search_logreg,\n",
    "    X=X_rfe,\n",
    "    y=y,\n",
    "    cv=5,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "print(f\"accuracy: {results_log['test_score'].mean()}\")\n",
    "print(f\"accuracy: {results_log['estimator'][0].best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "accuracy: [0.80052]\n",
      "accuracy: {'clf__learning_rate': 0.1, 'clf__max_iter': 175, 'clf__max_leaf_nodes': 220, 'clf__min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "hgbc = HistGradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__learning_rate\": [0.1],\n",
    "    \"clf__max_iter\": [150, 175, 200],\n",
    "    \"clf__max_leaf_nodes\": [\n",
    "        210,\n",
    "        220,\n",
    "        230,\n",
    "    ],\n",
    "    \"clf__min_samples_leaf\": [5, 7, 10],\n",
    "}\n",
    "hgbc_pipe = Pipeline(\n",
    "    [\n",
    "        (\"clf\", hgbc),\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid_search_hgbc = GridSearchCV(\n",
    "    hgbc_pipe, param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "outer_valid = ShuffleSplit(n_splits=1, test_size=0.25, random_state=2)\n",
    "\n",
    "results = cross_validate(\n",
    "    estimator=grid_search_hgbc, X=X_rfe, y=y, cv=outer_valid, return_estimator=True\n",
    ")\n",
    "\n",
    "print(f\"accuracy: {results['test_score']}\")\n",
    "print(f\"accuracy: {results['estimator'][0].best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The HistGradientBoostingClassifier seems to be slightly better than the other models in terms of accuracy. But I will choose the KNN because it uses a fraction of the features due to the feature selection. This choice aims to enhance the user experience in the frontend - fewer questions, more chances that the user will answer, or less time it consumes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
